\documentclass[10pt,letterpaper]{article}

\usepackage{ccn}
\usepackage{pslatex}
\usepackage{apacite}

\title{Disentangling via dynamics}
 
\author{{\large \bf Andrew David Zaharia$^\star$ (andrew.z@columbia.edu)} \\
  Mortimer B. Zuckerman Mind Brain Behavior Institute\\
  Columbia University, New York, NY 10027, USA
  \AND {\large \bf Benjamin Peters$^\star$ (bp2576@columbia.edu)} \\
  Mortimer B. Zuckerman Mind Brain Behavior Institute\\
  Columbia University, New York, NY 10027, USA
  \AND {\large \bf John Cunningham (jpc2181@columbia.edu)} \\
  Department of Statistics and Grossman Center\\
  Columbia University, New York, NY 10027, USA
  \AND {\large \bf Nikolaus Kriegeskorte (n.kriegeskorte@columbia.edu)} \\
  Mortimer B. Zuckerman Mind Brain Behavior Institute\\ Departments of Psychology, Neuroscience, and Electrical Engineering\\
  Columbia University, New York, NY 10027, USA
  \AND $^\star$ These authors contributed equally to this work}

%% AZ additions
\usepackage{graphicx,xcolor}
\graphicspath{{./figures/}}

% \hyphenation{auto-encoder}
\hyphenation{auto-encoders}
% \hyphenation{dis-entangle}

\begin{document}

\maketitle

\section{Abstract}
{
\bf
The abstract should be identical to the text version submitted in the webform and should not exceed 1,500 characters, including spaces and any special characters. The abstract should thus be relatively short. Aim for 150 words.
Max length is 200 words. Arbitrarily long German words like "Donaudampfschiffartskapit\"an" are not encouraged.
CCN has an interdisciplinary audience. Hence a good abstract should
(a) give context about what the problem is and why it matters 
(b) give the contents and explain what was done and what was found
(c) give a clear conclusion including what we learned and how it changes 
the way we think about the universe.
And because Konrad is writing this, he can not avoid shamelessly plugging
his writing guide:
\url{goo.gl/vC8tvf} See you at CCN.
}
\begin{quote}
\small
\textbf{Keywords:} 
add your choice of indexing terms or keywords; kindly use a
semicolon; between each term
\end{quote}


\section{Introduction}

A crucial function of visual processing systems, both artificial and biological, is to represent relevant information in visual scenes at higher levels of abstraction. This is typically achieved by a series of computations which first extract simple features, such as local edge orientation, then use those as the basis to construct increasingly complex feature detectors. In the primate brain, visual areas organized in a hierarchy in which increasingly complex features are represented in areas later in the hierarchy.

Comparing individual neurons at increasing levels in the hierarchy, their \textit{selectivity} and \textit{invariance} both increase \cite{Rust2010}. Here, ``selectivity'' refers to how %fully the subspace of all images that excite a given neuron spans the subspace of all images that excite all neurons within that visual area. The more specific a complex feature detector is, the smaller its piece of 
finely a neuron can discriminate different stimulus representations in a particular feature space (e.g. preferring a particular object type in an object-responsive area), and ``invariance'' refers to how tolerant the neuron is to changes in other stimulus properties (e.g. signaling the presence of that object regardless of its position). The result of these computations is the \textit{disentangling} of visual representations to ones which compactly and independently encode the true generative factors of the world \cite{DiCarlo2007}. In object recognition for example, such factors could be the object's identity, size, rotation, lighting, and color. In the deep learning community, this same concept of disentanglement has been proposed as a desirable final representation in deep neural networks (DNNs) and a justification for the intermediate levels of representation often found in them \cite{Bengio2009}.

% A fundamental goal in machine learning is to build algorithms which can learn to predict future states, given a set of training data. In order to make such a problem tractable, certain inductive biases are adopted which constrain the possible solutions to a smaller set. In the case of visual object recognition and classification, one commonly adopted inductive bias is that the appearance of a given object can be determined by a small set of independent generative factors, such as the object’s identity, size, rotation, lighting, and color. A learned representation having these properties is said to be \textit{disentangled} \cite{DiCarlo2007,Bengio2009}, that is, object properties with different semantic meanings are not distributed across latent variables.

How might disentangled representations develop in visual systems? The highest performing models on object recognition tasks for example, are DNNs which developed their representations through supervised learning on millions of images and their object labels. Yet developing biological systems typically don't have access to a teacher providing them the true generative factors of the world. Recent work on disentanglement has therefore focused on the unsupervised learning setting. %Variational autoencoders (VAEs) are a popular framework for learning, in an unsupervised manner, the probability distribution of a set of inputs by jointly optimizing
This was popularized by a variant on variational autoencoders (VAEs) \cite{Kingma2014}, called \textit{$\beta$-VAE}, claimed to learn more disentangled representations by treating the reconstruction error term in the VAE loss function as a regularizer \cite{Higgins2017}. By deemphasizing reconstruction error, a tighter bottleneck is placed on the information that can be represented, which can sometimes lead to less entangled representations. Other related methods have targeted a particular point on a rate-distortion curve \cite{Alemi2017}, or level of overlap of latent factors \cite{Mathieu2018}. These approaches, however, are quite general and do not necessarily lead to truly disentangled representations \cite{Alemi2017,Mathieu2018}.

We hypothesize that a further inductive bias is necessary to produce truly disentangled representations. Objects are not static; they exist in a continuous world. The putative generative factors that determine an object’s appearance are likely to remain stable (e.g., the object's identity) or vary smoothly and slowly over time (e.g., the object's position or rotation) \cite{Wiskott2002}. This method of feature learning could explain how biological systems develop.

We propose that a representation which factorizes static properties and their dynamics will lead to better disentanglement. Previous approaches using dynamics as inductive biases for unsupervised learning settings combined VAEs with recurrent neural networks and Kalman filters \cite{Krishnan2015}, probabilistic graphical models \cite{Karl2016,Johnson2016}, and linear dynamical systems \cite{Archer2016,Johnson2016,Watter2015,Fraccaro2017a}. The latter study specifically used linear dynamics to learn more disentangled representations.


\section{Experiments}

\begin{figure}%[t!]
  % \begin{center}
     \includegraphics[width=3.375in]{entangle_analysis_supervised_anddata.png}
     \includegraphics[width=3.375in]{entangle_analysis_betaVAE.png}
  % \end{center}
  \caption{\textbf{Circles dataset and varying levels of entangled representations. [PLACEHOLDER!]}}{(middle, but will be top) The circles dataset, with one generating factor changing in each column (from left to right: circle horizontal and vertical locations, Gaussian horizontal and vertical locations). (top, but will be middle) A perfectly disentangled representation. As one generative factor linearly increases, one unique latent variable also linearly increases while the rest are constant. (bottom) In entangled representations, as one generative factor changes, multiple latent factors change.}
  \label{fig:dataset}
\end{figure}

In order to assess the effects of adding dynamics into models of disentanglement, we must to first assess the level of disentanglement existing models can achieve in extremely simple settings where perfect disentanglement should be achievable. We constructed a simple dataset in which each image (32x32 pixels) contains a white circle are drawn over an isotropic Gaussian (see figure~\ref{fig:dataset}a). We randomly varied the positions of each objects while keeping size and intensity fixed. Therefore, there are 4 generative factors for this dataset: the horizontal and vertical position of each object. An ideal encoder for these images that is perfectly disentangled is one with four latent variables, where %a single variable uniquely and independently changes proportionally when a single generative factor is changed, for all four factors
each one uniquely and linearly maps to one of the four generative factors (see figure~\ref{fig:dataset}b). An entangled representation would be one in which multiple latent variables change when varying a single generative factor, and potentially nonlinearly (see figure~\ref{fig:dataset}c).

As a basic control, we wanted to verify that a perfectly disentangled encoder could be achieved by training a simple encoder network with supervision to map its four latent variables directly to the generative factors. The encoder network has four convolutional (conv) layers, each with a stride of 2, and a rectified linear (ReLU) output nonlinearity. It is followed by a fully connected (FC) layer that maps to the four latent factors. Figure~\ref{fig:dataset}b indeed shows the results from this experiment, demonstrating that this architecture is capable of perfect disentanglement on this very simple dataset.

We next trained $\beta$-VAEs with the same encoder network architecture and a decoder network with the same-sized FC and deconvolutional (deconv) layers in reverse, for different $\beta$ values. The resulting representations are entangled (figure~\ref{fig:dataset}c), and become less informative for higher $\beta$ values.

\bigskip

%\section{Acknowledgments}
%Place acknowledgments (including funding information) in a section at
%the end of the paper.

\bibliographystyle{apacite}
\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}
\bibliography{refs}

\end{document}
